<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformerの構造② (大学生・教員向け) - エンコーダ</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.0.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=M+PLUS+Rounded+1c:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body { margin: 0; padding: 0; font-family: 'M PLUS Rounded 1c', sans-serif; background-color: #f0f9ff; overflow: auto; }
        .slide { width: 1280px; min-height: 720px; margin: 0 auto; position: relative; overflow: auto; background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%); /* Green Gradient */ box-shadow: 0 10px 20px rgba(0,0,0,0.1); border-radius: 12px; padding: 40px; display: flex; flex-direction: column; }
        .encoder-block { border: 3px solid #3b82f6; /* Blue-600 */ border-radius: 10px; padding: 20px; background: rgba(219, 234, 254, 0.7); /* Blue-100 with transparency */ width: 90%; margin: 0 auto; }
        .component-box { background: white; border: 1px solid #93c5fd; /* Blue-300 */ border-radius: 6px; padding: 10px; margin-bottom: 15px; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
        .arrow { font-size: 1.5rem; color: #60a5fa; /* Blue-400 */ margin: 5px 0; }
        .highlight { background-color: #a7f3d0; padding: 2px 5px; border-radius: 3px; font-weight: bold; }
    </style>
</head>
<body>
    <div class="slide">
        <div class="flex justify-between items-center mb-6">
            <h1 class="text-4xl font-bold text-green-800">Transformerの構造②：エンコーダ<br>〜入力シーケンスの理解〜</h1>
            <i class="fas fa-layer-group text-blue-600 text-5xl"></i>
        </div>

       <div class="flex-grow flex flex-col items-center justify-center">
            <p class="text-xl text-center text-gray-700 mb-6">
                エンコーダは、入力されたシーケンス（例えば文）の意味的特徴と構造を抽出するための複数の層で構成されています。
            </p>

            <div class="encoder-block">
                <p class="text-center font-bold text-blue-700 mb-4">エンコーダの内部構造</p>

                <div class="text-center mb-3">
                    <p class="font-semibold">入力シーケンス: 「猫はかわいい」</p>
                </div>
                <div class="flex justify-center"><i class="fas fa-arrow-down arrow"></i></div>

                <div class="component-box max-w-md mx-auto">
                    <p class="font-bold text-blue-700">① 入力埋め込み (Input Embedding) と 位置エンコーディング (Positional Encoding)</p>
                    <p class="text-sm mt-1">各トークン（単語など）は、連続的なベクトル空間における表現に変換されます。さらに、シーケンス内のトークンの位置情報をモデルに伝えるために、位置エンコーディングが加算されます。</p>
                    <p class="text-xs text-gray-500">例: 「猫」「は」「かわいい」→ 各単語に対応するベクトル表現</p>
                </div>
                <div class="flex justify-center"><i class="fas fa-arrow-down arrow"></i></div>

                <div class="component-box max-w-md mx-auto">
                    <p class="font-bold text-blue-700">② マルチヘッド自己注意機構 (Multi-Head Self-Attention)</p>
                    <p class="text-sm mt-1">入力シーケンス内の各トークンが、同じシーケンス内の他の全てのトークンに対してどの程度関連性を持つかを計算します。複数の注意ヘッドを用いることで、様々な側面からの関連性を捉えることができます。</p>
                    <p class="text-xs text-gray-500">例: 「かわいい」が「猫」に強く注意を払うといった関連性を学習。</p>
                </div>
                <div class="flex justify-center"><i class="fas fa-arrow-down arrow"></i></div>

                <div class="component-box max-w-md mx-auto">
                    <p class="font-bold text-blue-700">③ 順伝播ネットワーク (Feed-Forward Network)</p>
                    <p class="text-sm mt-1">各トークンの注意機構の出力を、独立に処理する全結合層からなるネットワークです。非線形変換を適用し、表現力を高めます。</p>
                </div>
                <div class="flex justify-center"><i class="fas fa-arrow-down arrow"></i></div>

                <p class="text-xs text-center text-gray-500 mb-3">(実際には、自己注意機構と順伝播ネットワークの後には、残差接続（Residual Connection）と層正規化（Layer Normalization）が適用されます)</p>

                <div class="text-center mt-3">
                    <p class="font-semibold">出力: エンコードされた意味表現 (ベクトル)</p>
                    <p class="text-xs text-gray-500">デコーダの注意機構へ伝達</p>
                </div>

                <p class="text-center text-sm font-bold text-blue-800 mt-4">
                    この自己注意機構と順伝播ネットワークの組み合わせが、エンコーダ内で複数回繰り返されます。
                </p>
            </div>

            <div class="mt-6 bg-green-50 p-4 rounded-lg max-w-3xl text-center">
                <p class="font-bold text-green-800"><i class="fas fa-info-circle mr-1"></i>ポイント</p>
                <p class="text-sm text-gray-700">エンコーダにおける<span class="font-bold">自己注意機構</span>は、入力シーケンス内のトークン間の依存関係を明示的にモデル化する上で重要な役割を果たします。これにより、文脈を考慮した高精度な意味表現の抽出が可能になります。</p>
            </div>
        </div>

        <div class="absolute bottom-4 right-8 bg-white bg-opacity-70 rounded-full px-4 py-1">
            <span class="text-gray-600">14 / 48</span>
        </div>
    </div>
</body>
</html>